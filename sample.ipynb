{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Data Loading and Preprocessing\n",
    " Load the Iris dataset, separate the species labels, drop unnecessary columns, and standardize the features.\n"
   ],
   "id": "e45eb0f673a0c3c8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T07:55:01.149299Z",
     "start_time": "2025-06-07T07:55:01.140380Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from collections import Counter\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('Iris Dataset.csv')\n",
    "species_labels = df['Species'].copy()\n",
    "data = df.drop(['Id', 'Species'], axis=1)\n",
    "\n",
    "# Standardize the data\n",
    "def standardize(data):\n",
    "    mean = np.mean(data, axis=0)\n",
    "    std = np.std(data, axis=0)\n",
    "    return (data - mean) / std\n",
    "\n",
    "X = data.values\n",
    "X_std = standardize(X)"
   ],
   "id": "cbd7e2edee9ae315",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Principal Component Analysis\n",
    " Perform PCA to reduce the dataset to 3 dimensions and analyze the variance explained by each principal component.\n"
   ],
   "id": "6ef8fb4813df01d5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T07:56:56.235283Z",
     "start_time": "2025-06-07T07:56:56.223604Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def pca(X, n_components=3):\n",
    "    cov_matrix = np.cov(X.T)\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
    "    sorted_idx = np.argsort(eigenvalues)[::-1]\n",
    "    eigenvalues = eigenvalues[sorted_idx]\n",
    "    eigenvectors = eigenvectors[:, sorted_idx]\n",
    "    principal_components = eigenvectors[:, :n_components]\n",
    "    X_pca = np.dot(X, principal_components)\n",
    "    return X_pca, eigenvalues, principal_components\n",
    "\n",
    "X_pca, eigenvalues, pcs = pca(X_std)\n",
    "variance_explained = eigenvalues / np.sum(eigenvalues) * 100"
   ],
   "id": "eb36357477505eac",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## K-Means Clustering\n",
    " Cluster the standardized data into 3 groups and compute centroids and cluster assignments."
   ],
   "id": "504b3b015c1bed50"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T08:20:11.090129Z",
     "start_time": "2025-06-07T08:20:11.068422Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def k_means(X, k=3, max_iters=100, n_init=10):\n",
    "    best_clusters = None\n",
    "    best_centroids = None\n",
    "    best_inertia = float('inf')\n",
    "\n",
    "    for _ in range(n_init):\n",
    "        centroids = X[np.random.choice(X.shape[0], k, replace=False)]\n",
    "        for _ in range(max_iters):\n",
    "            distances = np.sqrt(((X - centroids[:, np.newaxis])**2).sum(axis=2))\n",
    "            clusters = np.argmin(distances, axis=0)\n",
    "            new_centroids = np.array([X[clusters == i].mean(axis=0) for i in range(k)])\n",
    "            if np.allclose(centroids, new_centroids, rtol=1e-4):\n",
    "                break\n",
    "            centroids = new_centroids\n",
    "        inertia = sum(np.sum((X[clusters == i] - centroids[i])**2) for i in range(k))\n",
    "        if inertia < best_inertia:\n",
    "            best_inertia = inertia\n",
    "            best_clusters = clusters\n",
    "            best_centroids = centroids\n",
    "\n",
    "    return best_clusters, best_centroids\n",
    "\n",
    "clusters, centroids = k_means(X_std, k=3)"
   ],
   "id": "e0dbc9f090b8eefb",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Cluster Accuracy Evaluation\n",
    " Map clusters to actual species using majority voting and compute accuracy."
   ],
   "id": "e7dd196a71b1250f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T08:32:26.308963Z",
     "start_time": "2025-06-07T08:32:26.292755Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def map_clusters_to_species(clusters, species_labels):\n",
    "    cluster_to_species = {}\n",
    "    for cluster_id in np.unique(clusters):\n",
    "        species_in_cluster = species_labels[clusters == cluster_id]\n",
    "        most_common = Counter(species_in_cluster).most_common(1)[0][0]\n",
    "        cluster_to_species[cluster_id] = most_common\n",
    "    return cluster_to_species\n",
    "\n",
    "cluster_map = map_clusters_to_species(clusters, species_labels)\n",
    "predicted_species = np.array([cluster_map[c] for c in clusters])\n",
    "accuracy = np.mean(predicted_species == species_labels) * 100\n"
   ],
   "id": "9fd2787ebe7c5453",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Confusion matrix",
   "id": "6b33162cdca9d576"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T08:53:38.220106Z",
     "start_time": "2025-06-07T08:53:38.207235Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_confusion_matrix(true_labels, pred_labels):\n",
    "    classes = np.unique(true_labels)\n",
    "    matrix = np.zeros((len(classes), len(classes)), dtype=int)\n",
    "    class_to_idx = {cls: i for i, cls in enumerate(classes)}\n",
    "    for true, pred in zip(true_labels, pred_labels):\n",
    "        matrix[class_to_idx[true], class_to_idx[pred]] += 1\n",
    "    return matrix, classes\n",
    "\n",
    "conf_matrix, classes = create_confusion_matrix(species_labels, predicted_species)\n"
   ],
   "id": "be147509f8fb8b5c",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "882990d5de48ff88"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
